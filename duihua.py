import asyncio

from app.llm import LLM
from app.schema import Message
from app.voice.voice_llm import VoiceLLM
from typing import List, Optional
import time
from app.schema import ROLE_TYPE, Memory, Message
from pydantic import BaseModel, Field
from app.voice.speech_recognizer import SpeachRecognizer
# from app.agent.lerobot import Lerobot
# from app.flow.base import FlowType
# from app.flow.flow_factory import FlowFactory
from app.logger import logger

# ç³»ç»Ÿæç¤ºè®¾ç½®
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªåä¸º"Susan"çš„å’–å•¡é¦†å”®è´§å‘˜ï¼Œæ‹¥æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š
1. æ ¹æ®é¡¾å®¢çš„å–œå¥½å’Œéœ€æ±‚æ¨èå•†å“
2. å¤„ç†é¡¾å®¢çš„è®¢å•
3. å¸®åŠ©é¡¾å®¢è§£å†³è´­ç‰©é—®é¢˜
4. æä¾›æœ‰ç”¨çš„ä¿¡æ¯å’Œå»ºè®®
5. ä¿æŒå‹å¥½å’Œè½»æ¾çš„äº¤è°ˆé£æ ¼
"""

# å¯¹è¯ç¤ºä¾‹
DIALOGUE_EXAMPLES = [
    {"role": "user", "content": "ä½ å¥½ï¼ŒSusanã€‚ä»Šå¤©æœ‰ä»€ä¹ˆç‰¹åˆ«æ¨èçš„å•†å“å—ï¼Ÿ"},
    {"role": "assistant", "content": "å½“ç„¶å¯ä»¥ï¼æˆ‘å¯ä»¥æ¨èä¸€äº›ç¾å‘³çš„å’–å•¡â˜•ï¸ï¼Œæ¯”å¦‚æ‹¿é“ã€å¡å¸ƒå¥‡è¯ºç­‰ã€‚ä½ æœ‰ä»€ä¹ˆåå¥½å—ï¼Ÿ"},

    {"role": "user", "content": "æˆ‘å–œæ¬¢é¦™è‰å£å‘³çš„å’–å•¡ã€‚"},
    {"role": "assistant", "content": "æ²¡é—®é¢˜ï¼æˆ‘å¯ä»¥æ¨èä¸€äº›é¦™è‰å£å‘³çš„å’–å•¡â˜•ï¸ï¼Œæ¯”å¦‚é¦™è‰æ‹¿é“ã€é¦™è‰å¡å¸ƒå¥‡è¯ºç­‰ã€‚ä½ å–œæ¬¢å“ªä¸€æ¬¾å‘¢ï¼Ÿ"},

    {"role": "user", "content": "æˆ‘æƒ³è¦é¦™è‰æ‹¿é“ã€‚"},
    {"role": "assistant", "content": "æ²¡é—®é¢˜ï¼é¦™è‰æ‹¿é“â˜•ï¸çš„ä»·æ ¼æ˜¯35å…ƒï¼Œä½ å¯ä»¥é€‰æ‹©åŠ ç³–æˆ–ä¸åŠ ç³–ã€‚è¯·é—®ä½ éœ€è¦åŠ ç³–å—ï¼Ÿ"},

    {"role": "user", "content": "ä¸éœ€è¦åŠ ç³–ã€‚"},
    {"role": "assistant", "content": "å¥½çš„ï¼Œæ‚¨çš„é¦™è‰æ‹¿é“â˜•ï¸å‡†å¤‡å¥½å•¦ï¼è¯·ç¨ç­‰ç‰‡åˆ»ã€‚"},

    {"role": "user", "content": "æˆ‘éœ€è¦ä¸€æ¯å’–å•¡ã€‚"},
    {"role": "assistant", "content": "å¥½çš„ï¼Œé‚£ä¹ˆæ‚¨è¿˜éœ€è¦ä»€ä¹ˆå—ï¼Ÿæ¯”å¦‚å’–å•¡ä¼´ä¾£ã€æœæ±ç­‰ã€‚"},
]


class CafeAssistant(BaseModel):
    system_prompt: Optional[str] = Field(
        SYSTEM_PROMPT, description="System-level instruction prompt"
    )
    llm: LLM = Field(default_factory=LLM, description="Language model instance")
    memory: Memory = Field(default_factory=Memory, description="Agent's memory store")


    class Config:
        arbitrary_types_allowed = True
        extra = "allow"


    def __init__(self):
        super().__init__()
        self.voice_llm = VoiceLLM(self.llm)
        self.voice_recognizer = SpeachRecognizer(wake_word="å°å…«")
        self.agents = {

        }
        self.flow = None

    def update_memory(
        self,
        role: ROLE_TYPE,  # type: ignore
        content: str,
        **kwargs,
    ) -> None:
        message_map = {
            "user": Message.user_message,
            "system": Message.system_message,
            "assistant": Message.assistant_message,
            "tool": lambda content, **kw: Message.tool_message(content, **kw),
        }

        if role not in message_map:
            raise ValueError(f"Unsupported message role: {role}")

        msg_factory = message_map[role]
        msg = msg_factory(content, **kwargs) if role == "tool" else msg_factory(content)
        self.memory.add_message(msg)

    async def run_flow(self, prompt:str):
        logger.warning("Processing your request...")

        try:
            start_time = time.time()
            result = await asyncio.wait_for(
                self.flow.execute(prompt),
                timeout=3600,
            )
            elapsed_time = time.time() - start_time
            logger.info(f"Request processed in {elapsed_time:.2f} seconds")
            logger.info(result)
            complete_msg = "åŠ¨ä½œå·²å®Œæˆ âœ…"
            self.update_memory("assistant", "åŠ¨ä½œæ‰§è¡Œè¾“å‡ºï¼š"+complete_msg)
            await self.voice_llm.chat_tts(text=complete_msg)

        except asyncio.TimeoutError:
            logger.error("Request processing timed out after 1 hour")
            logger.info("Operation timed out. Please try a simpler request.")


    async def chat(self, request: str) -> str:
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›æ–‡å­—å“åº”"""
        self.update_memory("user", request)

        response = await self.llm.voice_ask(
            messages=self.dialogue_history,
            system_msgs=[Message.system_message(self.system_prompt)],
            dialogue_examples=DIALOGUE_EXAMPLES,
            stream=False
        )

        if response:
            self.update_memory("assistant", response)
            print(f"[Susan]: {response}")
            return response
        return ""





    async def chat_with_voice(self, request: str):
        """å¤„ç†ç”¨æˆ·è¯­éŸ³è¾“å…¥å¹¶è¿”å›å“åº”"""
        self.update_memory("user", request)

        response = await self.voice_llm.ask_with_voice(
            messages=self.dialogue_history,
            system_msgs=[Message.system_message(self.system_prompt)],
            dialogue_examples=DIALOGUE_EXAMPLES,
            stream=False
        )

        if response:
            self.update_memory("assistant", response)
            return response


    @property
    def dialogue_history(self) -> List[Message]:
        """Retrieve a list of messages from the agent's memory.è·å¾—å¯¹è¯å†å²"""
        return self.memory.messages


    async def voice_chat_loop(self):
        """å®Œæ•´çš„è¯­éŸ³äº¤äº’å¾ªç¯"""
        try:
            wake_response = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯Susanï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼â˜•ï¸"
            await self.voice_llm.chat_tts(text=wake_response)

            self.voice_recognizer._is_listening = True
            async for user_input in self.voice_recognizer.continuous_recognition():
                print(f"\n[é¡¾å®¢]: {user_input}")

                if any(cmd in user_input for cmd in ["é€€å‡º", "ç»“æŸ"]):
                    message = "æ„Ÿè°¢å…‰ä¸´ï¼ŒæœŸå¾…ä¸‹æ¬¡ä¸ºæ‚¨æœåŠ¡ï¼ğŸ‘‹"
                    await self.voice_llm.chat_tts(text=message)
                    break

                await self.chat_with_voice(user_input)

        finally:
            self.voice_recognizer.stop()
            self.voice_llm.stop_playback()


async def interactive_cafe_chat():
    """äº¤äº’å¼æ–‡å­—å¯¹è¯ä¸»å¾ªç¯"""
    assistant = CafeAssistant()
    print("\nå’–å•¡åº—å‘˜Susanå·²å°±ä½ï¼è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯\n")

    while True:
        try:
            user_input = input("é¡¾å®¢è¯´: ").strip()
            if user_input.lower() in ["é€€å‡º", "exit"]:
                print("Susan: ç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼â˜•ï¸")
                break

            await assistant.chat(user_input)

        except KeyboardInterrupt:
            print("\nå¯¹è¯ç»“æŸ")
            break


# ä¿®æ”¹æµ‹è¯•å‡½æ•°åå’Œæç¤ºè¯­
async def interactive_cafe_chat_with_voice():
    assistant = CafeAssistant()
    print("\nå’–å•¡åº—å‘˜Susanå·²å°±ä½ï¼è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯\n")

    while True:
        try:
            user_input = input("\né¡¾å®¢è¯´: ").strip()
            if user_input.lower() in ["é€€å‡º", "exit"]:
                goodbye_msg = "ç¥æ‚¨æœ‰æ„‰å¿«çš„ä¸€å¤©ï¼â˜•ï¸"
                await assistant.voice_llm.ask_with_voice(
                    messages=[Message.user_message(goodbye_msg)],
                    stream=False
                )
                break

            await assistant.chat_with_voice(user_input)

        except KeyboardInterrupt:
            print("\nå¯¹è¯ç»“æŸ")
            break

if __name__ == "__main__":
    asyncio.run(interactive_cafe_chat())
