import asyncio
import numpy as np
import sounddevice as sd
from torch import device
import whisper
from typing import AsyncGenerator, Optional
from dataclasses import dataclass
from app.logger import logger

@dataclass
class AudioConfig:
    sample_rate: int = 16000
    channels: int = 1
    dtype: str = "float32"
    silence_threshold: float = 0.02
    min_voice_duration: float = 0.5

class SpeachRecognizer:
    def __init__(
        self,
        wake_word: str,  # å¿…é¡»ä¼ å…¥å”¤é†’è¯
        model_size: str = "base",
        device_index: Optional[int] = None,
    ):
        """
        ä¸¥æ ¼å”¤é†’è¯è¯†åˆ«å™¨ï¼ˆæ£€æµ‹åˆ°å”¤é†’è¯åæ‰å¼€å§‹æ­£å¼è¯†åˆ«ï¼‰

        å‚æ•°:
            wake_word: å¿…é¡»çš„å”¤é†’è¯ï¼ˆå¦‚"å°åŠ©æ‰‹"ï¼‰
            model_size: whisperæ¨¡å‹å¤§å°
            device_index: éŸ³é¢‘è¾“å…¥è®¾å¤‡ç´¢å¼•
        """
        self.model = whisper.load_model(model_size)
        self.config = AudioConfig()
        self.device_index = device_index if device_index is not None else sd.default.device[0]
        self.wake_word = wake_word.lower()
        self._is_listening = False
        self.device()  # æ£€æŸ¥è®¾å¤‡å…¼å®¹æ€§
        logger.info(f"ğŸ§ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {self.device_index}")
        logger.info(f"ğŸ¤– è¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆï¼Œå”¤é†’è¯: '{self.wake_word}'")
        

    async def _record_audio_chunk(self, duration: float) -> np.ndarray:
        """å½•åˆ¶éŸ³é¢‘ç‰‡æ®µ"""
        recording = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: sd.rec(
                int(duration * self.config.sample_rate),
                samplerate=self.config.sample_rate,
                channels=self.config.channels,
                device=self.device_index,
                dtype=self.config.dtype,
                blocking=True,
            ),
        )
        return recording.squeeze()

    def device(self):
        try:
            sd.check_input_settings(
                device=self.device_index,
                samplerate=self.config.sample_rate,
                channels=self.config.channels
            )
        except sd.PortAudioError as e:
            logger.error(f"Device incompatibility: {str(e)}")
            logger.info("Please select from the following valid input devicesï¼š")
            for i, dev in enumerate(sd.query_devices()):
                if dev["max_input_channels"] > 0:
                    logger.info(f"Index {i}: {dev['name']}")
            exit(1)

    async def _vad_process(self, audio_data: np.ndarray) -> bool:
        """è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆè·³è¿‡é™éŸ³ç‰‡æ®µï¼‰"""
        energy = np.mean(np.abs(audio_data))
        result = energy > self.config.silence_threshold
        logger.debug(f"ğŸ”Š è¯­éŸ³æ´»åŠ¨æ£€æµ‹: {'æœ‰è¯­éŸ³' if result else 'æ— è¯­éŸ³'}")
        return result

    async def _check_wake_word(self, audio_data: np.ndarray) -> bool:
        """ä¸¥æ ¼æ£€æµ‹å”¤é†’è¯ï¼ˆä¸“ä¸ºå”¤é†’ä¼˜åŒ–ï¼‰"""
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)

        # å”¤é†’è¯æ£€æµ‹ä¸“ç”¨å‚æ•°ï¼ˆæé«˜å“åº”é€Ÿåº¦ï¼‰
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.model.transcribe(
                audio_data,
                language="zh",
                no_speech_threshold=0.6,           # æ›´é«˜é˜ˆå€¼é¿å…è¯¯å”¤é†’
                temperature=0.0,                   # ç¦ç”¨éšæœºæ€§
                condition_on_previous_text=False,  # ä¸ä¾èµ–ä¸Šæ–‡
            ),
        )
        detected = self.wake_word in result["text"].strip().lower()
        logger.debug(f"ğŸ‘‚ å”¤é†’è¯æ£€æµ‹: {'æ£€æµ‹åˆ°' if detected else 'æœªæ£€æµ‹åˆ°'}å”¤é†’è¯ '{self.wake_word}'")
        return detected

    async def wait_for_wake_word(self) -> None:
        """é˜»å¡ç›´åˆ°æ£€æµ‹åˆ°å”¤é†’è¯"""
        self._is_listening = True
        logger.info(f"ğŸ”‡ ä¼‘çœ ä¸­ï¼Œç­‰å¾…å”¤é†’è¯: '{self.wake_word}'...")

        while self._is_listening:
            audio_data = await self._record_audio_chunk(1.0)  # 1ç§’ç‰‡æ®µæé«˜å”¤é†’è¯æ£€æµ‹ç‡

            if await self._vad_process(audio_data) and await self._check_wake_word(audio_data):
                logger.info(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯ï¼å¼€å§‹ç›‘å¬...")
                return

    async def continuous_recognition(self) -> AsyncGenerator[str, None]:
        """æ­£å¼è¯­éŸ³è¯†åˆ«ï¼ˆå¿…é¡»åœ¨æ£€æµ‹åˆ°å”¤é†’è¯åè°ƒç”¨ï¼‰"""
        try:
            while self._is_listening:
                audio_data = await self._record_audio_chunk(5)

                if not await self._vad_process(audio_data):
                    continue

                if audio_data.dtype != np.float32:
                    audio_data = audio_data.astype(np.float32)

                result = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.model.transcribe(
                        audio_data,
                        language="zh",
                        no_speech_threshold=0.3,
                        temperature=0.2,
                    ),
                )

                text = result["text"].strip()
                if text:
                    logger.info(f"ğŸ—£ï¸ è¯†åˆ«ç»“æœ: {text}")
                    yield text

        finally:
            self.stop()

    def stop(self):
        """åœæ­¢è¯†åˆ«"""
        self._is_listening = False
        logger.info("ğŸ›‘ è¯†åˆ«å·²åœæ­¢")
